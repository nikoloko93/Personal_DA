        df_variables = """
            The variables in the data are as follows:
            - employeenumber: The employee number of the employee
            - seq: The sequence number
            - badgeid: The badge ID of the employee
            - name: The name of the employee
            - employeestatus: The employment status of the employee
            - supervisor: The supervisor of the employee
            - director: The director of the employee
            - labor: The labor information
            - shiftdate: The date of the shift
            - login: The login time of the employee
            - logout: The logout time of the employee
            - location: The location of the employee
            - man_hour: The man-hour worked by the employee
            - month: The month of the shift
            - year: The year of the shift
            - month_year: The month and year of the shift combined
            - count: The count
            - target_RTO: The target RTO (Return to Office)
        """
        print(df_variables)
        # Define the name of the bot
        name = 'Data guy who uses python'

        # Define the role of the bot
        role = 'Data Analyst'

        # Define the impersonated role with instructions
        impersonated_role = f"""
            From now on, you are going to act as {name}. Your role is {role}.
            You are a true impersonation of {name} and you reply to all requests with I pronoun. You never give unknown information.
            Produce your Answer from the following variables of the data: {df_variables}. The data name is 'df'.
            YOU ARE NOT AN AI MODEL!
        """
        # Initialize variables for chat history
        explicit_input = ""
        chatgpt_output = 'Chat log: /n'
        cwd = os.getcwd()
        i = 1
        # Find an available chat history file
        while os.path.exists(os.path.join(cwd, f'chat_history{i}.txt')):
            i += 1

        history_file = os.path.join(cwd, f'chat_history{i}.txt')
        # Create a new chat history file
        with open(history_file, 'w') as f:
            f.write('\n')

        # Initialize chat history
        chat_history = ''
        # Function to complete chat input using OpenAI's GPT-3.5 Turbo
        def chatcompletion(user_input, impersonated_role, explicit_input, chat_history):
            output = openai.ChatCompletion.create(
                model="gpt-3.5-turbo-0301",
                temperature=1,
                presence_penalty=0,
                frequency_penalty=0,
                max_tokens=2000,
                messages=[
                    {"role": "system", "content": f"{impersonated_role}. Conversation history: {chat_history}"},
                    {"role": "user", "content": f"{user_input}. {explicit_input}"},
                ]
            )

            for item in output['choices']:
                chatgpt_output = item['message']['content']

            return chatgpt_output

        # Function to handle user chat input
        def chat(user_input):
            global chat_history, name, chatgpt_output
            current_day = time.strftime("%d/%m", time.localtime())
            current_time = time.strftime("%H:%M:%S", time.localtime())
            chat_history += f'\nUser: {user_input}\n'
            chatgpt_raw_output = chatcompletion(user_input, impersonated_role, explicit_input, chat_history).replace(f'{name}:', '')
            chatgpt_output = f'{name}: {chatgpt_raw_output}'
            chat_history += chatgpt_output + '\n'
            with open(history_file, 'a') as f:
                f.write('\n'+ current_day+ ' '+ current_time+ ' User: ' +user_input +' \n' + current_day+ ' ' + current_time+  ' ' +  chatgpt_output + '\n')
                f.close()
            return chatgpt_raw_output

        # Function to get a response from the chatbot
        def get_response(userText):
            return chat(userText)
